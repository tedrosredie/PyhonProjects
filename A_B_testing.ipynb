{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsL/f+EEhwIKt4YpDw2xrh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A/B testing is a method of comparing two versions of a single variable, typically by testing a subject's response to version A against version B, and determining which of the two is more effective. This is often used in web design, marketing, and product development to understand user behavior and optimize outcomes.\n",
        "\n"
      ],
      "metadata": {
        "id": "nbMaI_QvficL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a step-by-step example of A/B testing using Python:\n",
        "\n",
        "# **1. Define the Problem and Hypothesis**\n",
        "Let's say a company wants to increase the click-through rate (CTR) on its website's call-to-action (CTA) button.\n",
        "\n",
        "   ***Null Hypothesis (H0)***: There is no significant difference in CTR between the original CTA button (Control) and the new CTA button (Variant).\n",
        "\n",
        "   ***Alternative Hypothesis (H1)***: The new CTA button (Variant) will have a significantly higher CTR than the original CTA button (Control).\n",
        "\n",
        "# **2. Data Collection**\n",
        "To perform an A/B test, you need to collect data from two groups: a control group that sees the original version and a variant group that sees the new version."
      ],
      "metadata": {
        "id": "nGHzpllSgOBQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlAskLo_dzMb",
        "outputId": "9049b937-1c30-467b-c296-a27e7352f535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined A/B Test Data:\n",
            "     group  clicked\n",
            "0  control        1\n",
            "1  control        1\n",
            "2  control        1\n",
            "3  control        1\n",
            "4  control        1\n",
            "\n",
            "Data Summary:\n",
            "         count  sum  mean\n",
            "group                    \n",
            "control   1000  100  0.10\n",
            "variant   1000  120  0.12\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Simulate data for Control Group (Original CTA)\n",
        "# Let's say 1000 users saw the original CTA, and 100 clicked\n",
        "control_impressions = 1000\n",
        "control_clicks = 100\n",
        "control_data = {'group': ['control'] * control_impressions,\n",
        "                'clicked': [1] * control_clicks + [0] * (control_impressions - control_clicks)}\n",
        "\n",
        "# Simulate data for Variant Group (New CTA)\n",
        "# Let's say 1000 users saw the new CTA, and 120 clicked\n",
        "variant_impressions = 1000\n",
        "variant_clicks = 120\n",
        "variant_data = {'group': ['variant'] * variant_impressions,\n",
        "                'clicked': [1] * variant_clicks + [0] * (variant_impressions - variant_clicks)}\n",
        "\n",
        "# Create DataFrames\n",
        "df_control = pd.DataFrame(control_data)\n",
        "df_variant = pd.DataFrame(variant_data)\n",
        "\n",
        "# Combine the data\n",
        "df_ab_test = pd.concat([df_control, df_variant], ignore_index=True)\n",
        "\n",
        "print(\"Combined A/B Test Data:\")\n",
        "print(df_ab_test.head())\n",
        "print(\"\\nData Summary:\")\n",
        "print(df_ab_test.groupby('group')['clicked'].agg(['count', 'sum', 'mean']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Calculate Key Metrics**\n",
        "Calculate the CTR for both the control and variant groups."
      ],
      "metadata": {
        "id": "r5ptEAhKfri3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "control_ctr = control_clicks / control_impressions\n",
        "variant_ctr = variant_clicks / variant_impressions\n",
        "\n",
        "print(f\"\\nControl Group CTR: {control_ctr:.4f}\")\n",
        "print(f\"Variant Group CTR: {variant_ctr:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YA7Ne8vfuJb",
        "outputId": "7acacf58-9dbb-4897-fbae-f66865a93098"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Control Group CTR: 0.1000\n",
            "Variant Group CTR: 0.1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Perform Statistical Significance Test (Chi-Squared Test)**\n",
        "To determine if the observed difference in CTR is statistically significant, we can use a chi-squared test."
      ],
      "metadata": {
        "id": "tXCOiER_fwu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create a contingency table\n",
        "# Rows: clicked, not clicked\n",
        "# Columns: control, variant\n",
        "contingency_table = np.array([[control_clicks, variant_clicks],\n",
        "                              [control_impressions - control_clicks, variant_impressions - variant_clicks]])\n",
        "\n",
        "print(\"\\nContingency Table:\")\n",
        "print(contingency_table)\n",
        "\n",
        "chi2, p_value, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"\\nChi-squared statistic: {chi2:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Define significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(f\"\\nSince the p-value ({p_value:.4f}) is less than alpha ({alpha}), we reject the null hypothesis.\")\n",
        "    print(\"There is a statistically significant difference in CTR between the control and variant groups.\")\n",
        "    if variant_ctr > control_ctr:\n",
        "        print(\"The Variant CTA button performed better.\")\n",
        "    else:\n",
        "        print(\"The Control CTA button performed better.\")\n",
        "else:\n",
        "    print(f\"\\nSince the p-value ({p_value:.4f}) is greater than alpha ({alpha}), we fail to reject the null hypothesis.\")\n",
        "    print(\"There is no statistically significant difference in CTR between the control and variant groups.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMXJ7QVnf03C",
        "outputId": "81619663-05e8-49de-8103-453ee6cc360a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Contingency Table:\n",
            "[[100 120]\n",
            " [900 880]]\n",
            "\n",
            "Chi-squared statistic: 1.8437\n",
            "P-value: 0.1745\n",
            "\n",
            "Since the p-value (0.1745) is greater than alpha (0.05), we fail to reject the null hypothesis.\n",
            "There is no statistically significant difference in CTR between the control and variant groups.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Interpretation of Results**\n",
        "In this example, if the p-value is less than 0.05 (a common significance level), it suggests that the observed difference in CTR is unlikely to have occurred by chance, and the new CTA button has a statistically significant impact. If the p-value is greater than 0.05, it means we don't have enough evidence to say that the new button is better."
      ],
      "metadata": {
        "id": "lou_O5fFf5an"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Make a Decision**\n",
        "Based on the statistical analysis, you can make an informed decision about whether to implement the new CTA button. If the variant performs significantly better, you would deploy it to all users. If not, you might need to iterate on the design or try a different approach.\n",
        "\n",
        "This code provides a basic framework. In a real-world scenario, you would also consider:\n",
        "\n",
        "   **Sample Size Calculation**: Determining the necessary number of impressions to detect a meaningful difference with sufficient statistical power.\n",
        "\n",
        "   **Duration of the Test**: Running the test long enough to account for daily and weekly variations in user behavior.\n",
        "\n",
        "   **Other Metrics**: Analyzing other relevant metrics beyond CTR, such as conversion rates or revenue.\n",
        "\n",
        "   **Segmentation**: Analyzing results across different user segments.\n",
        "\n",
        "   **Guardrail Metrics**: Monitoring other metrics that should not be negatively impacted by the change.\n"
      ],
      "metadata": {
        "id": "RswmgDM2f9AD"
      }
    }
  ]
}